{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junhyeonghong/anaconda3/envs/visualai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from typing import Any, Callable, Optional, Tuple, Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_config = {\n",
    "    \"base\" :\n",
    "        {\"num_layers\" : 12, \"embed_dim\"  : 768, \"mlp_dim\" : 3072, \"num_heads\" : 12},\n",
    "    \"large\" :\n",
    "        {\"num_layers\" : 24, \"embed_dim\"  : 1024, \"mlp_dim\" : 4096, \"num_heads\" : 16},\n",
    "    \"huge\" :\n",
    "        {\"num_layers\" : 32, \"embed_dim\"  : 1280, \"mlp_dim\" : 5120, \"num_heads\" : 16}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patch2Vector(nn.Module):\n",
    "    def __init__ (self, patch_size, channel, embed_dim, num_patches, embed_type = 'conv', ):\n",
    "        super().__init__()\n",
    "        if embed_type =='conv':\n",
    "            self.projection = nn.Sequential(\n",
    "                nn.Conv2d(channel, embed_dim, kernel_size=patch_size, stride=patch_size),\n",
    "                Rearrange('batch (embed_dim) h w -> batch (h w) embed_dim')\n",
    "            )\n",
    "        elif embed_type == 'flatten': #proposed method in original VIT\n",
    "            self.projection = nn.Sequential(\n",
    "                Rearrange('batch c (h p1) (w p2) -> batch (h w) (p1 p2)', p1 = patch_size, p2 = patch_size),\n",
    "                nn.Linear(patch_size**2*channel, embed_dim),\n",
    "            )\n",
    "        else :\n",
    "            raise NotImplementedError(\"embed_type only 'conv' or flat \")\n",
    "        self.cls_token= nn.Parameter(torch.randn(1, 1, self.embed_dim)) #shape (1, 1, embed_dim)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(self.num_patches + 1, self.embed_dim)) #shape (num_patches+1, embed_dim)\n",
    "    def forward(self, x):\n",
    "        x = self.projection(x)# b,c,h,w -> b (h*w)/p^2 c*p^2 : batch num_patches embed_dim\n",
    "        batch = x.shpae[0]\n",
    "        x_cls = repeat(self.cls_token(), '1 1 e -> b 1 e', b=batch) \n",
    "        embedding = torch.cat(x_cls, x, dim=1) + self.pos_embedding # b n+1 e. add cls_token \n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadSelfAtteintion(nn.module):\n",
    "    def __init__(self, embed_dim, num_heads, drop_out):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.scaling = (embed_dim//num_heads)**-0.5\n",
    "        \n",
    "        self.qkv = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim*3), \n",
    "            Rearrange('b n (qkv d) -> qkv b n d' , qkv = 3),\n",
    "            Rearrange('qkv b n (h d) -> qkv b h n d', h = num_heads)\n",
    "            )\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "        self.o = nn.Linear(embed_dim, embed_dim)\n",
    "    def forward(self, x):\n",
    "        q, k, v= self.qkv(x) #b h n d\n",
    "        \n",
    "        att_score = torch.matmul(q,k.transpose(-2,-1))*self.scaling # [b h (n d)]@[b h (d n)] -> b h n n, @ is mat mul  \n",
    "        att_score = torch.softmax(att_score, dim = -1)\n",
    "        att_score = self.dropout(att_score)\n",
    "        \n",
    "        att = torch.matmul(att_score, v) # [b h (n n)] @ [b h (n d)] -> b h n d\n",
    "        att = rearrange(att, 'b h n d -> b n (h d)')\n",
    "        \n",
    "        return self.o(att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.module):\n",
    "    def __init__(self, embed_dim, mlp_dim, drop_out):\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop_out),\n",
    "            nn.Linear(mlp_dim,embed_dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, drop_out):\n",
    "        self.MSA = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            MultiheadSelfAtteintion(embed_dim, num_heads, drop_out),\n",
    "            )\n",
    "        self.FF = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            FeedForward(embed_dim, mlp_dim, drop_out),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "    def forward(self, x):\n",
    "        x = self.MSA(x) + x\n",
    "        x = self.dropout(x)\n",
    "        x = self.FF(x) + x\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class \n",
    "class VIT(nn.Module):\n",
    "    def __init__(self, *, image_size : Tuple[int, int, int], patch_size : int, num_classes : int, embed_type :str = 'conv', vit_type :str = 'base' ,pred_type : str = 'cls_token', dropout = 0., embed_dropout = 0.):\n",
    "        super().__init__()\n",
    "        assert vit_type in ('base', 'large', 'huge'), f\"vit_type must be 'base' or 'large' or 'huge'. but {vit_type}\"\n",
    "        assert pred_type in ('mean', 'cls_token'), f\"pred_type must be 'mean' or 'cls_token'. but {pred_type}\"\n",
    "        self.pred_type = pred_type\n",
    "        self.num_classes = num_classes\n",
    "        self.channel , self.height,self.width = image_size\n",
    "        assert not (self.height%patch_size or self.width%patch_size)  , f\"image size must be divisible by patch size,({self.height},{self.width}) can't devide by {patch_size} \"\n",
    "        self.num_patches = (self.height*self.width)//patch_size**2\n",
    "        self.patch_size = patch_size\n",
    "        self.config = vit_config[vit_type]\n",
    "        for k, v in self.config.items(): setattr(self, k, v)\n",
    "        \n",
    "        self.att_dropout_ratio = dropout\n",
    "        self.embed_dropout_ratio = embed_dropout\n",
    "        \n",
    "        assert self.embed_dim==self.patch_size**2*self.channel, f\"embed dimension of VIT-{vit_type} : {self.embed_dim}. but {self.patch_size**2*self.channel} \" \n",
    "        ###patch embedding\n",
    "        self.patch2vec = Patch2Vector(patch_size,self.channel, self.embed_dim, self.num_patches, embed_type)\n",
    "        self.embed_dropout = nn.Dropout(embed_dropout)\n",
    "        ###Tansformer Encoder\n",
    "        self.encoder = nn.ModuleList([EncoderBlock(self.embed_dim, self.num_heads, self.mlp_dim, dropout) for _ in range(self.num_layers)])\n",
    "        ###classifier\n",
    "        self.classifier = nn.Linear(self.embed_dim, num_classes)\n",
    "    def forward(self,x : torch.Tensor):\n",
    "        \"\"\"\n",
    "        x : (batch, channel, height, width)\n",
    "        \"\"\"\n",
    "        if len(x.shape)==4:\n",
    "            pass\n",
    "        elif len(x.shape)==3:\n",
    "            x = x.unsqueeze(dim=0)\n",
    "        else :\n",
    "            raise ValueError(f\"input dimension only allowed by (batch, channel, height, width) or (channel, height, width)\")\n",
    "        assert x.shape[-2]==self.height and x.shape[-1]==self.width, f\"expected height and width are {(self.height, self.width)} but {x.shape}\"\n",
    "        x = self.patch2vec(x) \n",
    "        x = self.embed_dropout(x) #batch num_patches+1 embed_dim\n",
    "        \n",
    "        x = self.Encoder(x) #batch num_patches+1 embed_dim\n",
    "        x = x.mean(dim=1) if self.pred_type=='mean' else x[:,0] # b n+1 e -> b e\n",
    "        #class token을 이용해 예측하는 경우 b n e 중 n의 첫번째에 해당하는 벡터이므로 이를 이용, 평균을 이용하는 경우 n에 대한 평균\n",
    "        #VIT 논문에서는 class token인 Z^0_L을 이용함\n",
    "        return self.classifier(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visualai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
